{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-195.871045</td>\n",
       "      <td>-14843.084171</td>\n",
       "      <td>5.532140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1217.183964</td>\n",
       "      <td>-4068.124621</td>\n",
       "      <td>4.416082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.138451</td>\n",
       "      <td>4413.412028</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.824242</td>\n",
       "      <td>15474.760647</td>\n",
       "      <td>1.094119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-768.812047</td>\n",
       "      <td>-7963.932192</td>\n",
       "      <td>1.870536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>192.093461</td>\n",
       "      <td>-12677.139687</td>\n",
       "      <td>3.456229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-118.048303</td>\n",
       "      <td>-27479.657522</td>\n",
       "      <td>9.407845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-38.987574</td>\n",
       "      <td>3599.957386</td>\n",
       "      <td>2.999579</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-31.315888</td>\n",
       "      <td>-15289.241646</td>\n",
       "      <td>3.882981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.379493</td>\n",
       "      <td>-9020.326833</td>\n",
       "      <td>7.759002</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1            f2        f3    y\n",
       "0  -195.871045 -14843.084171  5.532140  1.0\n",
       "1 -1217.183964  -4068.124621  4.416082  1.0\n",
       "2     9.138451   4413.412028  0.425317  0.0\n",
       "3   363.824242  15474.760647  1.094119  0.0\n",
       "4  -768.812047  -7963.932192  1.870536  0.0\n",
       "5   192.093461 -12677.139687  3.456229  0.0\n",
       "6  -118.048303 -27479.657522  9.407845  1.0\n",
       "7   -38.987574   3599.957386  2.999579  0.0\n",
       "8   -31.315888 -15289.241646  3.882981  0.0\n",
       "9    55.379493  -9020.326833  7.759002  1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('task_b.csv')\n",
    "data=data.iloc[:,1:]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data[['f1', 'f2', 'f3']].values\n",
    "#print(X)\n",
    "\n",
    "X = data.drop(['y'], axis = 1).values\n",
    "y = data['y'].values\n",
    "\n",
    "feature_names = np.array(data.drop(['y'], axis = 1).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(weights, feature_names):\n",
    "    \n",
    "    abs_weights = np.abs(weights)\n",
    "\n",
    "    #get the sorting indices\n",
    "    feature_arg_index = np.argsort(abs_weights)[::-1]\n",
    "    \n",
    "    print('Absolute Weights')\n",
    "    for i, j in enumerate(feature_arg_index):\n",
    "\n",
    "        if i == len(feature_arg_index) - 1:\n",
    "            print(abs_weights[j])\n",
    "        else:\n",
    "            print(abs_weights[j], '>>', end =\" \")\n",
    "        \n",
    "            \n",
    "    #Printing the features importance\n",
    "    print('Features importance')\n",
    "    for i, j in enumerate(feature_arg_index):\n",
    "\n",
    "        if i == len(feature_arg_index) - 1:\n",
    "            print(feature_names[j])\n",
    "        else:\n",
    "            print(feature_names[j], '>>', end =\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 - Check feature importance using SGDClassifier with log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Weights\n",
      "62703.613476207865 >> 21919.91499637754 >> 6582.51216742502\n",
      "Features importance\n",
      "f2 >> f1 >> f3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_lr_clf = SGDClassifier(loss='log', n_jobs=1)\n",
    "sgd_lr_clf.fit(X, y)\n",
    "\n",
    "get_feature_importance(sgd_lr_clf.coef_[0], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "<b>Observation :</b> Absolute weights/coeficients are proportional to feature importance. \n",
    "              In above task f2 >> f1 >> f3 as per there respective absolute weights vectors values.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Check feature importance using SGDClassifier with hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Weights\n",
      "14440.987684835647 >> 5404.760433670973 >> 961.7157488115278\n",
      "Features importance\n",
      "f2 >> f3 >> f1\n"
     ]
    }
   ],
   "source": [
    "sgd_svm_clf = SGDClassifier(loss='hinge', n_jobs=1)\n",
    "sgd_svm_clf.fit(X, y)\n",
    "\n",
    "get_feature_importance(sgd_svm_clf.coef_[0], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "<b>Observation :</b> Absolute weights/coeficients are proportional to feature importance. \n",
    "              In above task f2 >> f3 >> f3 as per there respective absolute weights vectors values.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    \n",
    "    #Standardization of data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_x = standardize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 Check feature importance after standardization using  SGDClassifier with log loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Weights\n",
      "38.73296022323236 >> 9.21878730380539 >> 1.0925554272526696\n",
      "Features importance\n",
      "f3 >> f1 >> f2\n"
     ]
    }
   ],
   "source": [
    "sgd_lr_clf = SGDClassifier(loss='log', n_jobs=1)\n",
    "sgd_lr_clf.fit(standardized_x, y)\n",
    "\n",
    "get_feature_importance(sgd_lr_clf.coef_[0], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "<b>Observation :</b> Absolute weights/coeficients are proportional to feature importance. \n",
    "              After standardizing the columns, now the there is change in feature importance.\n",
    "              In above task f3 >> f1 >> f2 as per there respective absolute weights vectors values.\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2 Check feature importance after standardization using  SGDClassifier with hinge loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Weights\n",
      "38.217762384260716 >> 11.340481233346019 >> 0.440955859256167\n",
      "Features importance\n",
      "f3 >> f2 >> f1\n"
     ]
    }
   ],
   "source": [
    "sgd_svm_clf = SGDClassifier(loss='hinge', n_jobs=1)\n",
    "sgd_svm_clf.fit(standardized_x, y)\n",
    "\n",
    "get_feature_importance(sgd_svm_clf.coef_[0], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre> \n",
    "<b><font style='color:red'>Observation :</font>\n",
    "<font style='color:green'>Absolute weights/coeficients are proportional to feature importance. \n",
    "After standardizing the columns, now the there is change in feature importance.\n",
    "In above task f3 >> f2 >> f1 as per there respective absolute weights vectors values.\n",
    "</font>\n",
    "</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
